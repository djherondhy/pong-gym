# Pong com Aprendizado por ReforÃ§o

ğŸ® Este projeto implementa um jogo de Pong utilizando a biblioteca **Gym** para o ambiente e **Pygame** para a renderizaÃ§Ã£o. O agente utiliza uma rede neural treinada para controlar a raquete direita, enquanto a raquete esquerda pode ser controlada por um humano ou seguir automaticamente a bola.

## ğŸ“¦ DependÃªncias

Certifique-se de ter as seguintes bibliotecas instaladas:

```bash
pip install gym pygame tensorflow numpy
```

## âš™ï¸ Estrutura do CÃ³digo

### Classes e MÃ©todos Principais

### PongEnv
Classe que representa o ambiente do jogo.

- **`__init__()`**: Inicializa o ambiente, configura a tela, as raquetes, a bola e a rede neural.
- **`create_model()`**: Cria a rede neural para a tomada de decisÃ£o do agente.
- **`reset()`**: Reinicializa o jogo para um novo episÃ³dio.
- **`step(action)`**: Executa a aÃ§Ã£o do agente e atualiza a posiÃ§Ã£o da bola e das raquetes.
- **`render()`**: Renderiza o jogo na tela.
- **`train(num_episodes)`**: Treina a rede neural em mÃºltiplos episÃ³dios.

### Algoritmo de Aprendizado

O agente utiliza um algoritmo de Q-learning com uma rede neural para estimar os valores de Q para as aÃ§Ãµes possÃ­veis. A polÃ­tica epsilon-greedy Ã© utilizada para equilibrar exploraÃ§Ã£o e exploraÃ§Ã£o, permitindo que o agente aprenda a jogar ao longo do tempo.

## ğŸš€ Executando o Jogo

Para treinar o agente:
```bash
if __name__ == "__main__":
    env = PongEnv()
    num_episodes = 50  # NÃºmero de episÃ³dios para treinamento
    env.train(num_episodes)
```

Para jogar com o modelo treinado:
```bash
if __name__ == "__main__":
    env = PongEnv()
    model_path = 'pong_model.h5'
    model = tf.keras.models.load_model(model_path)

    state = env.reset()
    running = True
    while running:
        env.render()

        # AÃ§Ã£o do agente (rede neural) para a raquete direita
        q_values = model.predict(np.array([state]).reshape(1, -1))
        agent_action = np.argmax(q_values)

        # AÃ§Ã£o da raquete esquerda (humano ou automÃ¡tico)
        env.step(agent_action)

        next_state, _, done, _ = env.step(agent_action)
        state = next_state

        if done:
            state = env.reset()

    env.close()

```

## ğŸ¯ Objetivos

- Treinar um agente que jogue Pong de forma autÃ´noma.
- Experimentar com diferentes arquiteturas de rede neural e parÃ¢metros de treinamento.
- Permitir que o usuÃ¡rio jogue contra um agente treinado.
